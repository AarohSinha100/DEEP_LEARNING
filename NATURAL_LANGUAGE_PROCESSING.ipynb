{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1Y7yqABE5vDci6p0HoHmj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AarohSinha100/DEEP_LEARNING/blob/main/NATURAL_LANGUAGE_PROCESSING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to NLP Fundamentals in Tensorflow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be text or speech).\n",
        "\n",
        "Antoher common term for NLP problems is sequence to sequence problems. (seq2seq)"
      ],
      "metadata": {
        "id": "Sv-LhPJ3-3iX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for GPU"
      ],
      "metadata": {
        "id": "Zu9rOv3GF8sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WsNiXb2F-xp",
        "outputId": "797608f2-a320-46fe-faf9-7160622c5e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-f19ab5a2-bcee-ad7a-4e34-33d6088564bd)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the helper functions\n",
        "----->https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "id": "uxeZFdPWGLUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "#Import series of helper functions for the notebooks\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAIemgsCGTAi",
        "outputId": "4878d11a-e7f3-4e59-e3b9-475e07a5bf4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-07 17:42:03--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-07 17:42:05 (108 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we are going to be using is Kaggle's Introduction to NLP dataset (text samples of tweet labelled as disasters or not disasters)\n",
        "> So binary classification on diffrent tweets"
      ],
      "metadata": {
        "id": "iph3GSxdGmpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip #This is going to download the file from kaggle (nlp getting started)\n",
        "\n",
        "#Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\") #Helper Functions :)"
      ],
      "metadata": {
        "id": "1q2-D1G8Gr_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c4214a-957c-4e43-9e46-e4d16777befb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-07 17:42:09--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.99.128, 173.194.202.128, 173.194.203.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.99.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-06-07 17:42:09 (125 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VISUALIZE...VISUALIZE...VISUALIZE - Visualizing a text dataset\n",
        "\n",
        "To visuzalize our text data, we have to read them in. We are gonna use Pandas library"
      ],
      "metadata": {
        "id": "2SwXRTkyqiIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\") #Train data\n",
        "test_df = pd.read_csv(\"test.csv\") #Test Data\n",
        "\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "i-o8fktCrKYN",
        "outputId": "31cea54b-68a7-4feb-96f6-5440ea6e2e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38474c98-6795-4382-a0a9-abc842b91afe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38474c98-6795-4382-a0a9-abc842b91afe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-38474c98-6795-4382-a0a9-abc842b91afe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-38474c98-6795-4382-a0a9-abc842b91afe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking what 1 and 0 mean"
      ],
      "metadata": {
        "id": "xYDE1O-5r-6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"text\"][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7Itc5k-mr9Jh",
        "outputId": "7307f47b-e944-4a91-a550-1c71f8a6db52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Forest fire near La Ronge Sask. Canada'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a disaster tweet...means that 1 is for disaster and 0 for non disaster."
      ],
      "metadata": {
        "id": "XOIhSZ8jsID3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "train_df_shuffle = train_df.sample(frac=1, random_state=42) #sample shuffle the data (frac 1 means it will shuffle 100% of our data)"
      ],
      "metadata": {
        "id": "VMAuZUL4sDVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffle.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qBhG8Bnks1L6",
        "outputId": "9ccb9948-4a49-46a8-c4ca-137c135dcd42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a295d69b-f166-48e4-b5c0-792011e03f13\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a295d69b-f166-48e4-b5c0-792011e03f13')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a295d69b-f166-48e4-b5c0-792011e03f13 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a295d69b-f166-48e4-b5c0-792011e03f13');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.iloc[132].text #This is a non disaster tweet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LVJQbPJ9s3Tv",
        "outputId": "505e62f4-5856-4363-cef9-b321885db001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Aftershock back to school kick off was great. I want to thank everyone for making it possible. What a great night.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test data...\n",
        "test_df.head() #There is no target column here as we have to specify that"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_etRraA0tDpB",
        "outputId": "e4d9fa08-15a9-439d-9993-33160d3f122a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70fa034a-3b31-42c2-bc61-29cddad11880\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70fa034a-3b31-42c2-bc61-29cddad11880')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70fa034a-3b31-42c2-bc61-29cddad11880 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70fa034a-3b31-42c2-bc61-29cddad11880');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How many examples of each class do we have\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpYQK6RatM2q",
        "outputId": "027d0b98-ccb1-40f9-b831-303cd1440743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If data is unbalanced in any other projects - https://www.tensorflow.org/tutorials/structured_data/imbalanced_data"
      ],
      "metadata": {
        "id": "BJkxonWetxiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The total number of tweets in triaining set is {len(train_df)}\")\n",
        "print(f\"The total number of tweets in the test set is {len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jxNhb_Ptafo",
        "outputId": "9983a154-10dc-433d-b97a-0e7db732f77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of tweets in triaining set is 7613\n",
            "The total number of tweets in the test set is 3263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's Visualize some random training samples"
      ],
      "metadata": {
        "id": "LcgV3lwZtlyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def get_random_tweet(dataset=train_df):\n",
        "  for i in range(0,5):\n",
        "    random_index = random.randint(0,len(dataset)+1)\n",
        "    try:\n",
        "      random_tweet = dataset.iloc[random_index].text\n",
        "      random_tweet_class = dataset.iloc[random_index].target\n",
        "      print(\"TEXT - \")\n",
        "      print(random_tweet)\n",
        "      if random_tweet_class == 0:\n",
        "        print(\"----->The tweet is non disastraous\")\n",
        "      else:\n",
        "        print(\"----->The tweet is a disaster\")\n",
        "    except:\n",
        "      print(\"No such dataset found or index might be our of range\")\n",
        "    \n",
        "    print(\" \")\n",
        "    print(\"-----------------------------------------------------------------------------------------------\")\n",
        "    print(\" \")"
      ],
      "metadata": {
        "id": "qTRlcC9uuG9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_tweet = get_random_tweet(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baizGwLPusRk",
        "outputId": "9f828a90-275e-4e9e-b3c7-980fcf5019ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXT - \n",
            "Stony Jackson is America's last hope as he leads an army of felons thus and army rejects against the army o Satan - http://t.co/0wbEcdMHQo\n",
            "----->The tweet is non disastraous\n",
            " \n",
            "-----------------------------------------------------------------------------------------------\n",
            " \n",
            "TEXT - \n",
            "A protest rally at Stone Mountain? Atleast they're not burning down buildings and looting store like some individuals do when they 'protest'\n",
            "----->The tweet is non disastraous\n",
            " \n",
            "-----------------------------------------------------------------------------------------------\n",
            " \n",
            "TEXT - \n",
            "Whirlwind Head Scissor on @alexhammerstone @kttape ktfounder #RemyMarcel #FroFroFroÛ_ https://t.co/B19z8Vi3td\n",
            "----->The tweet is non disastraous\n",
            " \n",
            "-----------------------------------------------------------------------------------------------\n",
            " \n",
            "TEXT - \n",
            "ng2x5 mhtw4fnet\n",
            "\n",
            "Watch Michael Jordan absolutely destroy this meme-baiting camper - FOXSportscom\n",
            "----->The tweet is non disastraous\n",
            " \n",
            "-----------------------------------------------------------------------------------------------\n",
            " \n",
            "TEXT - \n",
            "Ina Buted Girl Crush??\n",
            "----->The tweet is a disaster\n",
            " \n",
            "-----------------------------------------------------------------------------------------------\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Splitting dataset into training and validation sets"
      ],
      "metadata": {
        "id": "rKjE-r0Cu2dC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "#Use train test split to split training data into training and validaiton sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffle[\"text\"].to_numpy(),\n",
        "                                                                             train_df_shuffle[\"target\"].to_numpy(),\n",
        "                                                                             test_size=0.1, #Use 10 percent ot the data\n",
        "                                                                             random_state=42)\n",
        "#Train test split accepts numpy"
      ],
      "metadata": {
        "id": "sZwsaZuYwfPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the lengths\n",
        "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y7uXgyCx3JZ",
        "outputId": "09756c6f-13aa-463c-b70d-f824d83c8c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 762, 6851, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU2K4iwgyS1u",
        "outputId": "7a11f668-045d-4909-fdc6-681db9e097f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object),\n",
              " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### This Dats Is Still In Text Form...We'll have to convert it into numerical form before passing into the model for training"
      ],
      "metadata": {
        "id": "bWqWWZ9ayagP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting Text Data Into Numbers Using Tokenization And Embeddings\n",
        "\n",
        "When dealing with text problems, first thing we have to do is to convert text to numbers before building a model.\n",
        "\n",
        "There are a few ways to do this - \n",
        "* Tokenization - direct mapping of token (a token could be a word or a charecter) to a number\n",
        "* Embedding - creating a matrix of feature vector for each token"
      ],
      "metadata": {
        "id": "iHNsGZhhythM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Text Vectorization (tokenization)\n",
        "\n",
        ">Text Vectorizer\n",
        "The vocabulary for the layer must be either supplied on construction or learned via adapt(). When this layer is adapted, it will analyze the dataset, determine the frequency of individual string values, and create a vocabulary from them. This vocabulary can have unlimited size or be capped, depending on the configuration options for this layer; if there are more unique values in the input than the maximum vocabulary size, the most frequent terms will be used to create the vocabulary.\n",
        "\n",
        "The processing of each example contains the following steps:\n",
        "\n",
        "* Standardize each example (usually lowercasing + punctuation stripping)\n",
        "* Split each example into substrings (usually words)\n",
        "* Recombine substrings into tokens (usually ngrams) --N-grams are contiguous sequences of n items (characters, words, or other units) extracted from a given text--\n",
        "* Index tokens (associate a unique int value with each token)\n",
        "* Transform each example using this index, either into a vector of ints or a dense float vector."
      ],
      "metadata": {
        "id": "qthet89y4qY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGQL27Dj4ykZ",
        "outputId": "56e4c477-156c-4e3b-b8c8-5543d1e7cda4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have to map these text data into some numerical representation"
      ],
      "metadata": {
        "id": "5QvTItVf41Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "metadata": {
        "id": "XpG1gFMC4wjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">* max_tokens = None ---> #Define how many diffrent words can be there in the vocabulary (The vocabulary can be very big, so let this class only figure how may words are gonna be there adds <00V>)\n",
        ">* standardize=\"lower_and_strp_punctuations\" ---> We wanna remove unwanted punctuation and also all words must be like same lowercase...so this is the normalization in texts (just like rescaling 1/255. in images)\n",
        ">* split=\"whitespace\" ---> It is gonna split the worrds in whitespaces\n",
        ">* ngrams=None --->Create groups of n words, giving it None means leaving it on its own to specify\n",
        ">*  output_mode=int ---> How to map tokens into numbers\n",
        ">* output_sequence_lengt ---> Just like batches (how long)....we can limit the sequence lengths using this"
      ],
      "metadata": {
        "id": "YR6KdKkl6ez4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFAULT EXAMPLE  ----"
      ],
      "metadata": {
        "id": "QFfd2zT79oII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use default text vectorizer parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
        "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"
      ],
      "metadata": {
        "id": "6i0VwXZf4-xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fint the average number of tokens (words) in training tweets ---> WE ARE GONNA SET THE MAX LENGTH TO AVERAGE LENGTH OF TOKEN TWEETS SO AS TO KEEP OUR DATA SMALL\n",
        "round(sum([len(i.split()) for i in train_sentences]))/len(train_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EV8liLW71HB",
        "outputId": "3cbf3ea9-4994-4e37-d2b8-67b034c60eb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.901036345059115"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup text vectorization variables\n",
        "max_vocab_length = 10000 #Max number of words to have in our vocabulary\n",
        "max_length = 15 #Max length our sequences will need (e.g - how many words from a tweet our model sees)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "xH0VZFHq82FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer into training data\n",
        "\n",
        "text_vectorizer.adapt(train_sentences) #adapting the vectorizer to the training data"
      ],
      "metadata": {
        "id": "_AMH04A5989m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There is a flood in my street\"\n",
        "text_vectorizer([sample_sentence]) #It wants a list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USHxR30p_DG-",
        "outputId": "3131439f-0712-4056-c466-6302caf87a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 74,   9,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the max length was 15, the shape is also (1,15)\n",
        "\n",
        ">This sequence is 6 words long, after it we have zeros padded "
      ],
      "metadata": {
        "id": "ntkO1ILG_Q8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"The original text is:\\n{random_sentence}\\\n",
        "      \\n\\n Vectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UNAry3O_MRq",
        "outputId": "8a5aba41-5f29-4c19-fdac-c5ae34e44895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original text is:\n",
            "@burberryant bleeding on the brain don't know the cause      \n",
            "\n",
            " Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   1,  587,   11,    2, 1890,   63,  106,    2,  257,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspecting the number of unique words in our vocabulary the vectorizer has fgot in the train data\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() #Get all of the unique words in the training data\n",
        "top_5_words = words_in_vocab[:5] #Most common words the vectorizer found\n",
        "bottom_5_words = words_in_vocab[-5:] #Least occuring words\n",
        "\n",
        "print(f\"The number of words in vocab : {len(words_in_vocab)}\")\n",
        "\n",
        "print(f\"The 5 most common words: {top_5_words}\")\n",
        "print(f\"The 5 least common words: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP6H5hjs_ymv",
        "outputId": "f1dedf91-0084-4b8b-a3db-ed3674cc73a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of words in vocab : 10000\n",
            "The 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "The 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.EMBEDDING\n",
        "\n",
        ">Creating an Embedding Layer - Turns positive integers (indexes) into dense vectors of fixed size.\n",
        "--- e.g. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n",
        "\n",
        "To make our embedding layer, we are going to use the Tensorflow embedding Layer - https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "The Parameters we care most about our embedding layers are - \n",
        "* `input_dim` - This is the size of our vocabulary\n",
        "* `output_dim` - size of the output embedding layer...for example a value of 100 means each token gets represented by a vector 100 long\n",
        "* `input_length` - length of the sequences being passed to the embedding layer"
      ],
      "metadata": {
        "id": "C6M_wmyTA3ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                             output_dim=128,\n",
        "                             embeddings_initializer=\"uniform\",\n",
        "                             input_length=max_length)\n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59BECS54CFCX",
        "outputId": "5111df6e-cecf-4237-f57f-2fdb512de9c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7f7c93c248b0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"The original text :\\ {random_sentence}\\\n",
        "\\n\\n Embedded Version - \")\n",
        "#Embed random sentence (turn into dendse vectors of a fixed size)\n",
        "#We need to turn it first in the vectorizer as embedding turns positive \"INTEGER\" to vectors\n",
        "#Right now it is just words....let's create them into int\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ08eMdEDYHv",
        "outputId": "9c3cd9e0-8fce-47ba-8003-9ec8a73b8ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original text :\\ Cell Phone Shop : http://t.co/iOq051t5te #629 8-Pin Lightning Connector 2.1A Car Charger For Apple 5 5S 5C 6 6+ iÛ_ http://t.co/klxAUcNP5I\n",
            "\n",
            " Embedded Version - \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.04134491, -0.00159863,  0.01980717, ..., -0.01299115,\n",
              "          0.0208254 ,  0.0223966 ],\n",
              "        [ 0.04732246,  0.02330602,  0.01713059, ..., -0.00070627,\n",
              "         -0.0137905 ,  0.01193313],\n",
              "        [-0.01710637, -0.02210553,  0.04437119, ...,  0.03841979,\n",
              "         -0.04540541,  0.03306251],\n",
              "        ...,\n",
              "        [-0.00472503,  0.02831844,  0.00463182, ...,  0.02907172,\n",
              "          0.016291  , -0.03763517],\n",
              "        [-0.0477449 ,  0.00169557, -0.01968043, ..., -0.0308611 ,\n",
              "         -0.03043112,  0.03798098],\n",
              "        [-0.04275444,  0.01556275,  0.04594073, ..., -0.03424549,\n",
              "          0.04486721, -0.02724433]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0], random_sentence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUT0k7xrEBAh",
        "outputId": "b9b80b2b-2f97-48e0-b3bd-4bfa91999d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.04134491, -0.00159863,  0.01980717,  0.00624888, -0.04232964,\n",
              "         0.0364141 , -0.02397284,  0.02803009,  0.03450369,  0.01417526,\n",
              "         0.03585858,  0.0310072 , -0.03001758,  0.0453001 , -0.00524889,\n",
              "         0.043879  , -0.02537545,  0.04853258,  0.03155625, -0.02957367,\n",
              "        -0.01504999, -0.00284743,  0.04324925, -0.01922392,  0.03336864,\n",
              "        -0.00439656, -0.04556565, -0.03103905, -0.00157691, -0.01409397,\n",
              "        -0.02171482,  0.0088232 ,  0.0337415 ,  0.02348901, -0.04449555,\n",
              "         0.03573899,  0.0064647 , -0.02717172, -0.02008392, -0.0072505 ,\n",
              "        -0.03425287, -0.00225637,  0.03921964, -0.01866356,  0.01740218,\n",
              "         0.03202671, -0.04500021, -0.02912926, -0.01140256,  0.03807548,\n",
              "        -0.01365334,  0.01280094, -0.0001724 ,  0.0213665 , -0.00145358,\n",
              "         0.02268598, -0.04026543, -0.01695202, -0.00162592, -0.02174668,\n",
              "        -0.01850837,  0.04003472,  0.01672799,  0.04641683,  0.0463728 ,\n",
              "         0.02109519,  0.02214558,  0.02038005,  0.00386431,  0.03075994,\n",
              "        -0.04125124,  0.00116744,  0.0185538 ,  0.03678764,  0.03467888,\n",
              "        -0.04278246,  0.00318759,  0.04689386,  0.02918715,  0.02961216,\n",
              "        -0.01287429, -0.00736207,  0.04602152,  0.00146744,  0.04658866,\n",
              "        -0.01142772, -0.02778023, -0.01039916,  0.0492886 , -0.03266399,\n",
              "        -0.04352311,  0.02486971, -0.00721569,  0.04933211, -0.03418212,\n",
              "         0.03272425, -0.03291013, -0.01571242,  0.04848678, -0.01198377,\n",
              "        -0.04277394,  0.00174029,  0.03867287, -0.02592319,  0.00523666,\n",
              "         0.00580715, -0.04594904,  0.02824653, -0.04809577,  0.03063413,\n",
              "        -0.00939317, -0.0409279 ,  0.03695009, -0.04284172,  0.00057908,\n",
              "        -0.0262681 , -0.01958317,  0.01472037,  0.02510685, -0.013121  ,\n",
              "        -0.00017542, -0.00824462, -0.00063213, -0.02327112, -0.02220323,\n",
              "        -0.01299115,  0.0208254 ,  0.0223966 ], dtype=float32)>,\n",
              " <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.04134491, -0.00159863,  0.01980717,  0.00624888, -0.04232964,\n",
              "         0.0364141 , -0.02397284,  0.02803009,  0.03450369,  0.01417526,\n",
              "         0.03585858,  0.0310072 , -0.03001758,  0.0453001 , -0.00524889,\n",
              "         0.043879  , -0.02537545,  0.04853258,  0.03155625, -0.02957367,\n",
              "        -0.01504999, -0.00284743,  0.04324925, -0.01922392,  0.03336864,\n",
              "        -0.00439656, -0.04556565, -0.03103905, -0.00157691, -0.01409397,\n",
              "        -0.02171482,  0.0088232 ,  0.0337415 ,  0.02348901, -0.04449555,\n",
              "         0.03573899,  0.0064647 , -0.02717172, -0.02008392, -0.0072505 ,\n",
              "        -0.03425287, -0.00225637,  0.03921964, -0.01866356,  0.01740218,\n",
              "         0.03202671, -0.04500021, -0.02912926, -0.01140256,  0.03807548,\n",
              "        -0.01365334,  0.01280094, -0.0001724 ,  0.0213665 , -0.00145358,\n",
              "         0.02268598, -0.04026543, -0.01695202, -0.00162592, -0.02174668,\n",
              "        -0.01850837,  0.04003472,  0.01672799,  0.04641683,  0.0463728 ,\n",
              "         0.02109519,  0.02214558,  0.02038005,  0.00386431,  0.03075994,\n",
              "        -0.04125124,  0.00116744,  0.0185538 ,  0.03678764,  0.03467888,\n",
              "        -0.04278246,  0.00318759,  0.04689386,  0.02918715,  0.02961216,\n",
              "        -0.01287429, -0.00736207,  0.04602152,  0.00146744,  0.04658866,\n",
              "        -0.01142772, -0.02778023, -0.01039916,  0.0492886 , -0.03266399,\n",
              "        -0.04352311,  0.02486971, -0.00721569,  0.04933211, -0.03418212,\n",
              "         0.03272425, -0.03291013, -0.01571242,  0.04848678, -0.01198377,\n",
              "        -0.04277394,  0.00174029,  0.03867287, -0.02592319,  0.00523666,\n",
              "         0.00580715, -0.04594904,  0.02824653, -0.04809577,  0.03063413,\n",
              "        -0.00939317, -0.0409279 ,  0.03695009, -0.04284172,  0.00057908,\n",
              "        -0.0262681 , -0.01958317,  0.01472037,  0.02510685, -0.013121  ,\n",
              "        -0.00017542, -0.00824462, -0.00063213, -0.02327112, -0.02220323,\n",
              "        -0.01299115,  0.0208254 ,  0.0223966 ], dtype=float32)>,\n",
              " 'C')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling a text dataset and Running a series of experiments\n",
        "\n",
        "Now we got a way to turn out text sequences into numbers, let's start modelling with a series of experiments\n",
        "\n",
        "* Model 0: Naive Bayes (baseline)\n",
        "* Model 1: Feed-Forward Neural Network (dense model)\n",
        "* Model 2: LSTM Model (RNN)\n",
        "* Model 3: GRU Model (RNN)\n",
        "* Model 4: Bidirectional-LSTM Model (RNN)\n",
        "* Model 5: 1D Convolutional Neural Netowrk (CNN)\n",
        "* Model 6: Transfer Learning Model\n",
        "* Model 7: Same as Model 6 with 10% of training data\n",
        "\n"
      ],
      "metadata": {
        "id": "vKyirwAKEeCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL 0: BASELINE MODEL (NAIVE BAYES CLASSIFIER) - 79.27%\n",
        "\n",
        "To create our baseline, we will use multinomial naive bayes model"
      ],
      "metadata": {
        "id": "gsCtjrg5FKVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#Create tokenization and modelling pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\",TfidfVectorizer()),#convert words to numbers (name, function)\n",
        "    (\"clf\",MultinomialNB()) #model the text\n",
        "])\n",
        "\n",
        "#Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "0BmUINiCJeRO",
        "outputId": "429a5892-33ec-4a53-d80e-716b4212569f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRg-wAYuKwqd",
        "outputId": "81303594-5f2d-4420-a44d-972a17c5d29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18fHHrNALHbs",
        "outputId": "4e289416-3676-4d1b-afe1-0556c98b2205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "7n6wlJOQLZ7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get baseline results\n",
        "baseline_results = calculate_results(val_labels, baseline_preds)"
      ],
      "metadata": {
        "id": "guqyb4OrMvtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_v1KWtzNrxj",
        "outputId": "50f3d97f-6e2e-4596-c9c7-af12eeed57f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL 1: FEED FORWARD NEURAL NETWORK MODEL (DENSE MODEL)"
      ],
      "metadata": {
        "id": "WNxp_5DsNt7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Tensorboard Callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save tendorboard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "OSDZGnpLrvoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and it predicts multile results form 1 sentence)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
      ],
      "metadata": {
        "id": "Lq262CnBr-2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAT2pOcQs2KY",
        "outputId": "6e60826e-c984-47ef-9bfd-ceb5896c211d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "-dp1VtNPs6Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get a summary of the model\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "u4O2P1UuuJ_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c10301-1b72-496d-c1b3-de44ed3677df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, \n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlOdJ30ItULp",
        "outputId": "d947dc48-4176-4846-d254-7f3cf5b57823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20230607-174214\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 20s 70ms/step - loss: 0.6124 - accuracy: 0.6911 - val_loss: 0.5375 - val_accuracy: 0.7612\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4419 - accuracy: 0.8168 - val_loss: 0.4671 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3473 - accuracy: 0.8612 - val_loss: 0.4561 - val_accuracy: 0.7874\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.2850 - accuracy: 0.8889 - val_loss: 0.4667 - val_accuracy: 0.7861\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.2385 - accuracy: 0.9123 - val_loss: 0.4772 - val_accuracy: 0.7835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "THE MODEL IS NOT IMPROVING MUCH"
      ],
      "metadata": {
        "id": "FWYkASBKuYWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like our baseline is outperforming our model_1"
      ],
      "metadata": {
        "id": "kd_hOMoITHEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing learned embeddings"
      ],
      "metadata": {
        "id": "MhiGoEH8Ss4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the vocabulary from the text vectorization\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "metadata": {
        "id": "-6j9dBMVTPHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c60afa34-9792-4eab-9c3c-43daf222fc7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the odest common words"
      ],
      "metadata": {
        "id": "_D9-La0LT1JS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "BonWIqq_TlOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e8f2bd-2087-4358-f26d-c1058ff2b6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the weight matrix of the embedding layer\n",
        "# (these are the numerical representations of each token in our training data, which have been learned for 5 epochs)\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0] #if layer not found, check the model summary and the name of the embedding layer\n",
        "embed_weights"
      ],
      "metadata": {
        "id": "i5eC5iyVT6zP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb68e577-6494-449b-807b-1ade25a5f50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.03431485,  0.06492641,  0.01804921, ..., -0.0056389 ,\n",
              "        -0.03644315,  0.01503701],\n",
              "       [-0.02758117,  0.04756122, -0.00203538, ..., -0.01978559,\n",
              "        -0.03826602,  0.043572  ],\n",
              "       [-0.01813884,  0.01713146, -0.00213831, ..., -0.01177805,\n",
              "        -0.05879504, -0.00293622],\n",
              "       ...,\n",
              "       [-0.04855562, -0.02351548,  0.02598368, ...,  0.01663053,\n",
              "        -0.00732379,  0.02907452],\n",
              "       [ 0.00419331,  0.03924385,  0.03547308, ...,  0.08242538,\n",
              "        -0.0572527 ,  0.05284252],\n",
              "       [-0.04716341,  0.09481687,  0.06677979, ...,  0.10053758,\n",
              "        -0.04731078,  0.08862591]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embed_weights.shape) #same size as vocab size and embedding_dim (output_dim of our embeding layer)"
      ],
      "metadata": {
        "id": "0cYO0G9nUTbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a6b6525-4ff3-4fd2-9b3b-5bb21a9195ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every token is embedded into a 128 dimension vector"
      ],
      "metadata": {
        "id": "65SOKOBQUtMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now we have got the embeding matrix pur model has learned to represent tokens, let's see how we can visualize it\n",
        "\n",
        "To do so Tensorflow has a handy tool called `Projector` and also tensorflow has an incredible guide for word embeddings"
      ],
      "metadata": {
        "id": "VK_pdz8sUqNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embedding files (we got this from tensorflow word embeding documentation)\n",
        "import io\n",
        "out_v = io.open('vectors.tsv','w',encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv','w',encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index==0:\n",
        "    continue #skip 0, it's padding\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + '\\n')\n",
        "  out_m.write(word+\"\\n\")\n",
        "\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "1cyfBJawVTC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download files from colab t upload to projector (again from docs)\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "#   files.download('vectors.tsv')\n",
        "#   files.download('metadata.tsv')\n",
        "# except:\n",
        "#   pass"
      ],
      "metadata": {
        "id": "ALdUgBlMWPjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNN's are useful for the sequence data.\n",
        "\n",
        "The premise of a recurrent neural networks is to use the representation of a previous input to aid the representation of a later input"
      ],
      "metadata": {
        "id": "0CaL-ZaHXsR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL 2: LSTM (RNN MODEL)\n",
        "\n",
        "LSTM = Long Short Term Memory... this is one of the modst popular LSTM cells\n",
        "\n",
        "Our structure in RNN looks like this - \n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNN/Dense) ->Output (label probability)\n",
        "```"
      ],
      "metadata": {
        "id": "ym3ngrQdRbU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a lstm MODEL\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape) #shape of output layer from embedding\n",
        "x = layers.LSTM(64, return_sequences=True)(x) #When stacking RNN sequences together we need to return sequences\n",
        "print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "print(x.shape)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "print(x.shape)\n",
        "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXY_5xXZSQ9m",
        "outputId": "350aa889-235e-4b65-db6d-845aa9153fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 64)\n",
            "(None, 64)\n",
            "(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow_wNpLkTgP1",
        "outputId": "c87469af-30e2-4272-cf88-161c64d8be1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 15, 64)            49408     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,366,657\n",
            "Trainable params: 1,366,657\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "sKapDeRCVWnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_2_lstm\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADO3Vk5mViCz",
        "outputId": "de2cda69-0683-4dc2-914f-7eaa25110d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_lstm/20230607-174245\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 19s 64ms/step - loss: 0.2225 - accuracy: 0.9238 - val_loss: 0.5458 - val_accuracy: 0.7848\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1602 - accuracy: 0.9416 - val_loss: 0.6554 - val_accuracy: 0.7677\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.1331 - accuracy: 0.9486 - val_loss: 0.7409 - val_accuracy: 0.7782\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1065 - accuracy: 0.9606 - val_loss: 0.7822 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0885 - accuracy: 0.9653 - val_loss: 1.0057 - val_accuracy: 0.7625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make Prediction with LSTM Model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGQvb3dWVysN",
        "outputId": "5523e473-2f13-44c2-ff2a-e4e4e918eb69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.53715464e-03],\n",
              "       [5.70760131e-01],\n",
              "       [9.99943614e-01],\n",
              "       [7.54001886e-02],\n",
              "       [1.10835754e-04],\n",
              "       [9.99093175e-01],\n",
              "       [8.15781951e-01],\n",
              "       [9.99969482e-01],\n",
              "       [9.99940395e-01],\n",
              "       [7.67824471e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjreTsooWG8L",
        "outputId": "ff3c8a43-3447-4897-c240-2bbc1e51297d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate model 2 results\n",
        "model_2_results = calculate_results(val_labels, model_2_preds)"
      ],
      "metadata": {
        "id": "8us-fJZ6WbwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results"
      ],
      "metadata": {
        "id": "nJloogNyWiAI",
        "outputId": "75fb1948-6763-406d-91de-e9bd21e89481",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.24671916010499,\n",
              " 'precision': 0.7626600366229389,\n",
              " 'recall': 0.7624671916010499,\n",
              " 'f1': 0.7611077640788777}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL 3: GRU POWERED RNN\n",
        "\n",
        "Another Popoular and effective RNN component is the GRU or gated recurrent unit\n",
        "\n",
        "The Gru cell has similiar feature to a LSTM cells but has less parameters"
      ],
      "metadata": {
        "id": "Scl5ae5AWjjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Build an RNN using a GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64, return_sequences=True)(x)  #If u want to stack recurrent layer on top of each other, u coud put return sequences to True\n",
        "x = layers.LSTM(64, return_sequences=True)(x)\n",
        "x = layers.GRU(64)(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")\n"
      ],
      "metadata": {
        "id": "B7xSM_xwOydW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hRqXK80QU1h",
        "outputId": "8051d66c-7f88-4aff-e138-aebad5227da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 15, 64)            37248     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 15, 64)            33024     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 64)                24960     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,379,457\n",
            "Trainable params: 1,379,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile The Model\n",
        "model_3.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "fy74JfNuQXbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_history = model_3.fit(train_sentences,\n",
        "                             train_labels,\n",
        "                             epochs=5,\n",
        "                             validation_data=(val_sentences, val_labels),\n",
        "                             callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                    \"model_3_GRU\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-Vg4RhIRSs5",
        "outputId": "74dbd2ba-6c28-4c8b-8acd-220914f2303c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20230607-174316\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 19s 60ms/step - loss: 0.1386 - accuracy: 0.9517 - val_loss: 1.1127 - val_accuracy: 0.7730\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0744 - accuracy: 0.9691 - val_loss: 1.2159 - val_accuracy: 0.7703\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0670 - accuracy: 0.9698 - val_loss: 1.4386 - val_accuracy: 0.7638\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.0544 - accuracy: 0.9752 - val_loss: 1.5030 - val_accuracy: 0.7612\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.0495 - accuracy: 0.9758 - val_loss: 1.3448 - val_accuracy: 0.7664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some preidctions with our GRU Model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXhIMcPqRk9l",
        "outputId": "3ebb5835-c684-4cb5-f0d9-ccc7f1134f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.3558364e-04],\n",
              "       [6.6129124e-01],\n",
              "       [9.9998736e-01],\n",
              "       [2.6404136e-01],\n",
              "       [4.0404713e-05],\n",
              "       [9.9982989e-01],\n",
              "       [7.8701669e-01],\n",
              "       [9.9998665e-01],\n",
              "       [9.9998498e-01],\n",
              "       [8.3072782e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs)) #to remove that one dimension\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anPxoB4zRw_0",
        "outputId": "d79926d1-5272-43fe-dbb2-281c4a08289c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)"
      ],
      "metadata": {
        "id": "gYYQl4OhSEge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPrDq8nnSRCT",
        "outputId": "67d9d1b3-fe5c-4849-db49-31e47696a583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.64041994750657,\n",
              " 'precision': 0.7690247510270006,\n",
              " 'recall': 0.7664041994750657,\n",
              " 'f1': 0.7637309688758864}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL 4: BIDIRECTIONAL RNN\n",
        "\n",
        "Normal RNN goes from left to right, just like we read english sentence.... however a bidirectional RNN goes from right to left from left to right"
      ],
      "metadata": {
        "id": "hJUMXW3TTnnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a bidirectional RNN in Tensorflow\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "print(x.shape)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "x = layers.Bidirectional(layers.LSTM(64,return_sequences=True))(x)\n",
        "print(x.shape)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "print(x.shape)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR4PhWHdT-Ab",
        "outputId": "49b5d556-e8c2-4efb-8916-c4ef69f162c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15)\n",
            "(None, 15, 128)\n",
            "(None, 15, 128)\n",
            "(None, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhMpvXctV5F5",
        "outputId": "a2168300-ed1c-4d10-c15c-3b0fcb97184d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 15, 128)          98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              74496     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,453,441\n",
            "Trainable params: 1,453,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comple the model\n",
        "model_4.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "-USRFgZ0V6Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model\n",
        "history_model_4 = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                      \"model_4_bidirectional\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juHhxRZ5XQDk",
        "outputId": "3f5dbb44-396c-4107-936e-59f918937d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20230607-174405\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 20s 61ms/step - loss: 0.1051 - accuracy: 0.9679 - val_loss: 0.9474 - val_accuracy: 0.7703\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 25ms/step - loss: 0.0558 - accuracy: 0.9749 - val_loss: 1.2516 - val_accuracy: 0.7651\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0497 - accuracy: 0.9737 - val_loss: 1.2624 - val_accuracy: 0.7572\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.0449 - accuracy: 0.9781 - val_loss: 1.3980 - val_accuracy: 0.7507\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0408 - accuracy: 0.9794 - val_loss: 1.4847 - val_accuracy: 0.7585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with our bidirectional Model\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chjSKDcrXf92",
        "outputId": "22ef51b0-e84e-4ef0-8397-fa50ac41cfef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 2s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.4600038e-03],\n",
              "       [6.7174566e-01],\n",
              "       [9.9986947e-01],\n",
              "       [1.9296925e-01],\n",
              "       [2.8697863e-05],\n",
              "       [9.9982905e-01],\n",
              "       [9.9424970e-01],\n",
              "       [9.9994957e-01],\n",
              "       [9.9991775e-01],\n",
              "       [9.9530715e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert predprobs to pred labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))"
      ],
      "metadata": {
        "id": "N3Z6ZSQGXpdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b5_j4hZX5Vw",
        "outputId": "fd76601a-8652-4fd6-fd89-439eb1a29649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_results = calculate_results(val_labels,\n",
        "                                    model_4_preds)"
      ],
      "metadata": {
        "id": "HsrdDYMDX6al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krWgcv8bYAXB",
        "outputId": "1e57e25e-880e-4ee5-c348-a953bc958a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.8530183727034,\n",
              " 'precision': 0.7593999956661763,\n",
              " 'recall': 0.7585301837270341,\n",
              " 'f1': 0.7566051475454213}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL 5: CONVOLUTIONAL NEURAL NETWORKS FOR TEXTA ND OTHER SEQUENCES\n",
        "\n",
        "Typical structure of a Conv1D model for sequences (in our case text - )\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layers (typically conv1d + pooling) - > outputs\n",
        "```"
      ],
      "metadata": {
        "id": "hMqYTYHHYRZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXAMPLE\n"
      ],
      "metadata": {
        "id": "7gLbafDbdmmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our embedding Layer , Conv1D layer and maxpooling\n",
        "from tensorflow.keras import layers\n",
        "embedding_test = embedding(text_vectorizer([\"this is text sequence\"])) #turn target sequence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5,\n",
        "                        activation=\"relu\",\n",
        "                        padding=\"valid\")\n",
        "\n",
        "#Check what our output is\n",
        "conv_1d_output = conv_1d(embedding_test) #passing embedding_Test through our conv 1d layer\n",
        "#Setup a maxpool layer -> as we are using a conv layer, we need to use a maxpool layer\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output) #passing the conv1d output in the maxpool layer (\"get the feature with the hightst values\")\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEb6DS0oY73K",
        "outputId": "5bb83190-13c3-4de0-e80c-76a1b4de6397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "embedding = [1,15,128] -> as we have 1 sequence that is padded into a 15 length sequence as a 128 dimension feature vector\n",
        "conv1d = [1,11,32] -> as we have used valid padding and kernelsize of 5, our shape becomes 11 (we would have got 15 at padding=same),32 is filters\n",
        "maxpool - > takes everythiong and combines a s1 seqeuence of 32"
      ],
      "metadata": {
        "id": "3DlFU_98bR_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# conv_1d_output"
      ],
      "metadata": {
        "id": "ubLsmFv-bJja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_pool_output"
      ],
      "metadata": {
        "id": "5dnULFoZc_zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cerate 1D Convolutional Layer to mdel sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "\n",
        "x = layers.Conv1D(filters=64,\n",
        "                  kernel_size=5, #look at 5 words at a time\n",
        "                  activation=\"relu\",\n",
        "                  strides=1,\n",
        "                  padding=\"valid\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "#x = layers.Dense(64, activation=\"relu\")\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"Model_5_Conv2D\")\n",
        "\n",
        "#Compile the model\n",
        "model_5.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "RfxNo_s0dUCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "moel_5_history = model_5.fit(train_sentences,\n",
        "                             train_labels,\n",
        "                             epochs=5,\n",
        "                             validation_data=(val_sentences, val_labels),\n",
        "                             callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                    \"Conv1D\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V95GjI8erIx",
        "outputId": "9ae937b3-5f62-4630-bdfe-e48540c56ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20230607-174457\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 13s 52ms/step - loss: 0.1250 - accuracy: 0.9574 - val_loss: 0.8896 - val_accuracy: 0.7730\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0779 - accuracy: 0.9717 - val_loss: 1.0410 - val_accuracy: 0.7638\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0608 - accuracy: 0.9764 - val_loss: 1.1103 - val_accuracy: 0.7533\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.0544 - accuracy: 0.9794 - val_loss: 1.2069 - val_accuracy: 0.7625\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0526 - accuracy: 0.9768 - val_loss: 1.2466 - val_accuracy: 0.7520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions with our Conv1d model\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2exu_M6fCRT",
        "outputId": "199d6b44-e94b-4694-84c0-4642a0d19586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.7066775e-02],\n",
              "       [9.8264998e-01],\n",
              "       [9.9995899e-01],\n",
              "       [1.5569457e-02],\n",
              "       [8.2206320e-08],\n",
              "       [9.9690610e-01],\n",
              "       [9.5555007e-01],\n",
              "       [9.9995184e-01],\n",
              "       [9.9999928e-01],\n",
              "       [8.6901510e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#COnvert model_5_pred_probs to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApU7w72ifLw3",
        "outputId": "cf8caa08-2794-49ea-c72d-af7999ae6372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#results\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y9FOdR3fS4M",
        "outputId": "4dd59c11-e6f9-4386-f79d-cf250b057915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.19685039370079,\n",
              " 'precision': 0.7529888699847289,\n",
              " 'recall': 0.7519685039370079,\n",
              " 'f1': 0.7497885511234939}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY9Gec0cfa_8",
        "outputId": "aed68213-3a67-4437-adfb-3bf6f0398024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL 6: TENSORFLOW HUB PRETRAINED FEATURE EXTRACTOR\n",
        "Now we have built a few of our own model,let's try and use transfer learning for NLP, specifically for tensorflow\n",
        "\n",
        "MODEL LINK -> https://tfhub.dev/google/collections/universal-sentence-encoder/1"
      ],
      "metadata": {
        "id": "_-IS5lvOfdZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TgJU7fUFin8G",
        "outputId": "e2b65a5b-7fcd-44a4-f83a-a8a397c3b52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There is a flood in my street'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gets turned into numerical representation below"
      ],
      "metadata": {
        "id": "UHLxOiwVirQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence,\n",
        "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53V9vDbhf--j",
        "outputId": "c4aad549-11d6-4333-d5b2-47c6caacc65a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01602836  0.01068853  0.02425464 -0.0140577   0.01434427  0.08292626\n",
            "  0.0196337   0.06160139 -0.00352701 -0.01216416  0.00978647 -0.01248499\n",
            "  0.01232347  0.09748451  0.06141113 -0.03728352  0.01860887 -0.04669852\n",
            "  0.00413913 -0.06363907 -0.02469897  0.02713692  0.02284444 -0.0021003\n",
            " -0.00630592 -0.03964961  0.02220408  0.00115074 -0.03132182  0.00119528\n",
            " -0.0401255   0.04561896 -0.01530598 -0.00175914  0.02173134 -0.08450425\n",
            "  0.03340027  0.04604555 -0.02480251 -0.08681663  0.00702696 -0.00770477\n",
            " -0.01434536  0.07814163 -0.10676058 -0.05152996 -0.00858158 -0.03232232\n",
            " -0.03871096  0.02581472], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_samples.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh692G0SiY7X",
        "outputId": "a5d44bcb-0206-4c0c-e405-3dcfc5aa4eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creaqte Keras layer using the USE pretrained layer from tensorflow hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE\")"
      ],
      "metadata": {
        "id": "MTU5qMqQjCii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Model using  Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dense(64,activation=\"relu\",name=\"output_layer_1\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "],name=\"model_6_USE\")"
      ],
      "metadata": {
        "id": "q3c7jxlVkCTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "lBdwPa4Okbrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiEj4I70klM9",
        "outputId": "7e982c97-7d24-437b-84e7-c00475ebce5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " output_layer_1 (Dense)      (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a classifier on top of USE pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymr_s4tgkme8",
        "outputId": "ef1967f1-b2d2-49d9-f445-801fa7e0f88a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20230607-174604\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 14ms/step - loss: 0.5006 - accuracy: 0.7866 - val_loss: 0.4496 - val_accuracy: 0.8005\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4149 - accuracy: 0.8123 - val_loss: 0.4368 - val_accuracy: 0.8031\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3999 - accuracy: 0.8219 - val_loss: 0.4335 - val_accuracy: 0.8123\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.3923 - accuracy: 0.8254 - val_loss: 0.4294 - val_accuracy: 0.8110\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3849 - accuracy: 0.8297 - val_loss: 0.4270 - val_accuracy: 0.8136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Predictions\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_results = calculate_results(val_labels,\n",
        "                                    model_6_preds)\n",
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy5ZRYbjlIt8",
        "outputId": "cc24e208-d663-4c10-a921-fb242217f506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.36482939632546,\n",
              " 'precision': 0.8147394195152357,\n",
              " 'recall': 0.8136482939632546,\n",
              " 'f1': 0.8125379768469353}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwHJeD1klmqF",
        "outputId": "185d6eea-cbb3-4f31-9e20-b495344b3bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINALLY WE BEAT OUR BASELINE MODEL AFTER SO MANY EXPERIMENTS.....IN THE END THAT IS ONLY THE MACHINE LEARNING PRACTITIONER'S MOTTO...EXPERIMENT EXPERIMENT AND EXPERIMENT!!"
      ],
      "metadata": {
        "id": "C5HTJlVdmfiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGPrU1DslwRF",
        "outputId": "9c2abf93-0d6a-4dba-f2fc-6d4fa70057ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7613"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL 7: TF HUB PRETRAINED USE BUT WITH 10% OF PRETRAINED MODEL"
      ],
      "metadata": {
        "id": "A_w5CxYOm0b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create subsets of 10% of the training data\n",
        "train_10_percent = train_df_shuffle[[\"text\",\"target\"]].sample(frac=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "26V9yGuAnmfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences_10_percent = train_10_percent[\"text\"].to_list()"
      ],
      "metadata": {
        "id": "vPd6w3Y1ny84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_10_percent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4qwr20tn7Uq",
        "outputId": "9e9c009c-5f35-480a-fa41-a101d1297718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "761"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_10_percent = train_10_percent[\"target\"].to_list()"
      ],
      "metadata": {
        "id": "2cqw0wYtn9vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo37mDH-oLBM",
        "outputId": "864139b4-691f-4e16-99c5-86096a355092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(761, 761)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of targets in our subset of data\n",
        "train_10_percent[\"target\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGxGhej8oQ1b",
        "outputId": "b3f536e4-6930-4edd-aa54-bac59db9a64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    413\n",
              "1    348\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffle[\"target\"].value_counts()"
      ],
      "metadata": {
        "id": "bcZK36W3oXGg",
        "outputId": "308b9dba-ba02-4087-f1b3-73607eeaaa95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To recerate a model same as a previous model u created u can use the tf.keras.models.clone_model() method"
      ],
      "metadata": {
        "id": "BhdNKCPO98Ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's Build a model same as model 6\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "#Compile model\n",
        "model_7.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "#Summary\n",
        "model_7.summary()"
      ],
      "metadata": {
        "id": "qm6VkKYBocZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8043af68-6bda-4456-ebd0-55c6715809e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " output_layer_1 (Dense)      (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_7 = model_7.fit(train_sentences,\n",
        "                        train_labels,\n",
        "                        epochs=5,\n",
        "                        validation_data=(val_sentences, val_labels),\n",
        "                        callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                               \"model_7\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfDjPQjN-sXT",
        "outputId": "33173e98-d8ce-4470-c27b-6fb543526b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_7/20230607-175119\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.5030 - accuracy: 0.7815 - val_loss: 0.4533 - val_accuracy: 0.8005\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4157 - accuracy: 0.8159 - val_loss: 0.4456 - val_accuracy: 0.8045\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.4018 - accuracy: 0.8205 - val_loss: 0.4367 - val_accuracy: 0.8123\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3926 - accuracy: 0.8289 - val_loss: 0.4388 - val_accuracy: 0.8136\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3871 - accuracy: 0.8305 - val_loss: 0.4255 - val_accuracy: 0.8189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pred probs\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eQ20Q2_-_VL",
        "outputId": "32f86f5a-977c-4e98-aaf4-ca66d23ef4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 15ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate results\n",
        "model_7_results = calculate_results(val_labels, model_7_preds)"
      ],
      "metadata": {
        "id": "8tzsob2M_Ko_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuO9ukbF_UOU",
        "outputId": "51fb677a-7975-48d0-9962-440ea4cff994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.88976377952756,\n",
              " 'precision': 0.8196605460013572,\n",
              " 'recall': 0.8188976377952756,\n",
              " 'f1': 0.817984880977007}"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8s3F2dp_V45",
        "outputId": "6d5f9f15-a910-4019-9971-34e61ee8b7c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.36482939632546,\n",
              " 'precision': 0.8147394195152357,\n",
              " 'recall': 0.8136482939632546,\n",
              " 'f1': 0.8125379768469353}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model performs better than our model trained on full data. But this is model is outperforming......WHYYYY?\n",
        "\n",
        "This might be because - \n",
        ">* We have created the sets on shuffled data for model 6 (train test split)\n",
        ">* Model 7 sets were created directly from train_df_shuffled\n",
        ">* We have data leakage problem.....\n",
        ">* Two diffrent random sets are created....some of validation data is inside the 10_percent_data....so offcourse its prediction is going to be same"
      ],
      "metadata": {
        "id": "Y7ovn7EA_e5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixing the 10 percent split\n",
        "\n",
        "taking 10 percent of train test splits now...not from train df shuffles....so both val and train datas are completely diffrent"
      ],
      "metadata": {
        "id": "0vf_7qxY_ZRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a better dataset split\n",
        "train_sentences_10_percent_split = int((0.1)*len(train_sentences))\n",
        "train_sentences_10_percent_split = train_sentences[:train_sentences_10_percent_split] #685\n",
        "train_sentences_10_percent_split[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE9-RCc4BELj",
        "outputId": "145fcae0-fd4a-4251-c75a-dc8d7705e75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "       '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "       'destroy the free fandom honestly',\n",
              "       'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "       '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "       'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_10_percent_split = int((0.1)*len(train_labels))\n",
        "train_labels_10_percent_split = train_labels[:train_labels_10_percent_split]"
      ],
      "metadata": {
        "id": "Ehi_GuWvBuhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.Series(np.array(train_labels_10_percent_split)).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiJmFmMpCI5N",
        "outputId": "ea99a241-da76-411e-adfe-dcf9831797dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_7_updated = model_7.fit(train_sentences_10_percent_split,\n",
        "                        train_labels_10_percent_split,\n",
        "                        epochs=5,\n",
        "                        validation_data=(val_sentences, val_labels),\n",
        "                        callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                               \"model_7\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9C-q2oFCLv9",
        "outputId": "5cb88e1c-3467-461b-b11b-5bf74533cb5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_7/20230607-180730\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.3866 - accuracy: 0.8307 - val_loss: 0.4308 - val_accuracy: 0.8110\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.3660 - accuracy: 0.8453 - val_loss: 0.4331 - val_accuracy: 0.8136\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.3449 - accuracy: 0.8599 - val_loss: 0.4375 - val_accuracy: 0.8058\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.3289 - accuracy: 0.8672 - val_loss: 0.4420 - val_accuracy: 0.8058\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.3160 - accuracy: 0.8730 - val_loss: 0.4485 - val_accuracy: 0.8005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing the performance of each of our models"
      ],
      "metadata": {
        "id": "MPKKVoT_Da6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Making a pd dataset kind of things from result combinations\n",
        "all_model_results=pd.DataFrame({\"0_baseline\":baseline_results,\n",
        "                               \"2_lstm\":model_2_results,\n",
        "                               \"3_GRU\":model_3_results,\n",
        "                               \"4_Bidirectional\":model_4_results,\n",
        "                               \"5_Conv1D\":model_5_results,\n",
        "                               \"6_tfhub_use\":model_6_results})\n",
        "all_model_results = all_model_results.transpose()"
      ],
      "metadata": {
        "id": "zE0VihEaDer7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resuce the accuracy to the same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "metadata": {
        "id": "jCzK3qlHDvLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\",figsize=(10,7)).legend(bbox_to_anchor=(1.0,1.0))\n",
        "#To put legend outside"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "0NvltyecFaHw",
        "outputId": "465e4e32-7c59-416c-c0b6-02c532c21aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7ba876f070>"
            ]
          },
          "metadata": {},
          "execution_count": 134
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort model results by f1 score\n",
        "all_model_results.sort_values(\"f1\",ascending=False)[\"f1\"].plot(kind=\"bar\",figsize=(10,7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "H1HEs2hFGACK",
        "outputId": "5ef33a61-d3e9-4260-ee58-9b6a6658bf8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 135
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading our model training logs to Tensorboard.dev"
      ],
      "metadata": {
        "id": "fC159M4qHPPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View etnsorboard logs of transfer leanrning modelling experiments (plus all of our other models)\n",
        "# Upload Tensorboard dev records\n",
        "# !tensorboard dev upload --logdir ./model_logs/ \\\n",
        "#   --name \"NLP Modelling Experiments ZTM Course video codealong\" \\\n",
        "#   --one_shot #Exit the uploader once uploading is finished"
      ],
      "metadata": {
        "id": "x-Zsc7qAH0iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading the trained model\n",
        "\n",
        "There are 2 main formats to save a model in TensorFlow:\n",
        "1. HDF5\n",
        "2. The `SavedModel` format"
      ],
      "metadata": {
        "id": "PUEt5UnaIcNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results #The best model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ4Uuh72Jgi-",
        "outputId": "10fdeff4-ba34-418f-b211-b45a87c9b678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.36482939632546,\n",
              " 'precision': 0.8147394195152357,\n",
              " 'recall': 0.8136482939632546,\n",
              " 'f1': 0.8125379768469353}"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save this model\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "metadata": {
        "id": "uwbFQ2mPJnZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "2zzZI7K2KDn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load that back in (as object as it was from tensorflow hub)\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",\n",
        "                                            custom_objects={\"KerasLayer\":hub.KerasLayer})"
      ],
      "metadata": {
        "id": "lXmSii2DJuSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How does loaded model performs\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwRpb7-iKNQi",
        "outputId": "481f0414-84b0-4e01-bdea-02d4112481e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 17ms/step - loss: 0.4270 - accuracy: 0.8136\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4270358681678772, 0.8136482834815979]"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "* If our model is not the perfect, what examples are it getting wrong\n",
        "* and of these wrong examples which one is it getting *most* wrong (those will prediction probabilities closest to the opposite class)\n",
        "\n",
        "For example if our sample should be 0 but it is predicted 0.99999 (close to 1) and vice-versa"
      ],
      "metadata": {
        "id": "butE8CQ9KaNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a pretrained model fomr mrdbourke github\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DmgUqlYLu04",
        "outputId": "ff59f87a-55fa-423b-a022-baf4836b8b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-07 18:47:58--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.98.128, 74.125.197.128, 74.125.135.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.98.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‘08_model_6_USE_feature_extractor.zip’\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M  50.7MB/s    in 17s     \n",
            "\n",
            "2023-06-07 18:48:14 (55.4 MB/s) - ‘08_model_6_USE_feature_extractor.zip’ saved [960779165/960779165]\n",
            "\n",
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import previously trained model from github\n",
        "model_6_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n",
        "model_6_pretrained.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSOz80m4MMjY",
        "outputId": "2e9b73c3-bab4-4291-d1c1-5b46d9104ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 10ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42723119258880615, 0.8162729740142822]"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions with loaded model\n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretrained_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWlOZBO5Mee8",
        "outputId": "d07be838-936d-492c-d0b1-1204ad455d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 14ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame from the validation sentences and best performing model predictions\n",
        "val_df = pd.DataFrame({\"text\":val_sentences,\n",
        "                       \"target\":val_labels,\n",
        "                       \"preds\":model_6_pretrained_preds,\n",
        "                       \"pred_probs\":tf.squeeze(model_6_pretrained_pred_probs)})\n",
        "\n",
        "val_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MdCF2UyDLBxC",
        "outputId": "d7798c35-d993-4d0b-e8be-7c3673d99ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target  preds  \\\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0    0.0   \n",
              "1  FedEx no longer to transport bioterror germs i...       0    1.0   \n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1    1.0   \n",
              "3  @camilacabello97 Internally and externally scr...       1    0.0   \n",
              "4  Radiation emergency #preparedness starts with ...       1    1.0   \n",
              "\n",
              "   pred_probs  \n",
              "0    0.159757  \n",
              "1    0.747162  \n",
              "2    0.988749  \n",
              "3    0.196229  \n",
              "4    0.707808  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e00c278-dd2c-4586-9ee8-26e688725d5a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>preds</th>\n",
              "      <th>pred_probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.707808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e00c278-dd2c-4586-9ee8-26e688725d5a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e00c278-dd2c-4586-9ee8-26e688725d5a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e00c278-dd2c-4586-9ee8-26e688725d5a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"preds\"]].sort_values(\"pred_probs\",ascending=False)\n",
        "most_wrong[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5K7frYbvNUuK",
        "outputId": "88711845-c032-4ef3-bf5b-853fb75c2dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  target  preds  \\\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0    1.0   \n",
              "759  FedEx will no longer transport bioterror patho...       0    1.0   \n",
              "628  @noah_anyname That's where the concentration c...       0    1.0   \n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0    1.0   \n",
              "251  @AshGhebranious civil rights continued in the ...       0    1.0   \n",
              "393  @SonofLiberty357 all illuminated by the bright...       0    1.0   \n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0    1.0   \n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0    1.0   \n",
              "119  @freefromwolves GodsLove &amp; #thankU brother...       0    1.0   \n",
              "344  Air Group is here to the rescue! We have 24/7 ...       0    1.0   \n",
              "\n",
              "     pred_probs  \n",
              "31     0.910196  \n",
              "759    0.876982  \n",
              "628    0.852300  \n",
              "209    0.835454  \n",
              "251    0.827213  \n",
              "393    0.814816  \n",
              "109    0.810840  \n",
              "49     0.803122  \n",
              "119    0.766901  \n",
              "344    0.766625  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e4def6e-8239-45d8-b831-13a47672af59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>preds</th>\n",
              "      <th>pred_probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.814816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.810840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.803122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>@freefromwolves GodsLove &amp;amp; #thankU brother...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>Air Group is here to the rescue! We have 24/7 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e4def6e-8239-45d8-b831-13a47672af59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e4def6e-8239-45d8-b831-13a47672af59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e4def6e-8239-45d8-b831-13a47672af59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are false positives"
      ],
      "metadata": {
        "id": "J12xUd2OOifJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## making predictions on the test dataset\n"
      ],
      "metadata": {
        "id": "7OUNMuprN5Ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on tehst dataset and visualizing them\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz8NEG8GO8Ku",
        "outputId": "8b8de8a9-ef19-4ac9-9aeb-cd512fb3f0c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Just happened a terrible car crash',\n",
              " 'Heard about #earthquake is different cities, stay safe everyone.',\n",
              " 'there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all',\n",
              " 'Apocalypse lighting. #Spokane #wildfires',\n",
              " 'Typhoon Soudelor kills 28 in China and Taiwan']"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = random.sample(test_sentences, 10) #Gives 10 samples\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample])) #our model expects list as input\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"-----\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_WPh-wsPEbu",
        "outputId": "d26b3a4e-958e-4c10-9d12-691f776bf40d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 44ms/step\n",
            "Pred: 0, Prob: 0.04014390707015991\n",
            "Text:\n",
            "?Maybe someday we'll find the place where our dreams and reality collide.?\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Pred: 1, Prob: 0.8161736726760864\n",
            "Text:\n",
            "Sooooo shooting up movie theaters the new mass murderer wave??\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Pred: 1, Prob: 0.7939366698265076\n",
            "Text:\n",
            "Going to attempt the California fair again tomorrow hopefully we don't die in a tornado ??\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Pred: 0, Prob: 0.054553426802158356\n",
            "Text:\n",
            "@simplyysacred dude like he screams his soul out\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Pred: 0, Prob: 0.18610574305057526\n",
            "Text:\n",
            "Bayelsa poll: Plans by Patience Jonathan to hijack APC tickens http://t.co/eyn0E8pmJq\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Pred: 1, Prob: 0.9632819294929504\n",
            "Text:\n",
            "International News Û¢åÊ'Nigeria suicide bomb kills at least seven at market ' via @233liveOnline. Full story at http://t.co/MtTdvy6141\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Pred: 1, Prob: 0.7574476599693298\n",
            "Text:\n",
            ".POTUS #StrategicPatience is a strategy for #Genocide; refugees; IDP Internally displaced people; horror; etc. https://t.co/rqWuoy1fm4\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Pred: 0, Prob: 0.18110157549381256\n",
            "Text:\n",
            "'I lava you' ???? @kherr122\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Pred: 0, Prob: 0.05396916717290878\n",
            "Text:\n",
            "So in one episode they undo season 1. Kai joins FF Ren beats Aichi with Psy  and misaki gets crushed.  What the fuck?\n",
            "\n",
            "-----\n",
            "\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Pred: 1, Prob: 0.870972216129303\n",
            "Text:\n",
            "RedScareBot: Duck and Cover! RT tanstaafl23: noah_anyname Socialism means mass murder. Houze that for 'correlation'?\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_prob = tf.squeeze(model_6_pretrained.predict([\"mass murder happens'?\" ])) #our model expects list as input\n",
        "pred = tf.round(pred_prob)\n",
        "int(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Na4z4RIPwWh",
        "outputId": "e109b0d1-9740-4948-a51c-653132991ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 57ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g8S6si4HQeDS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}